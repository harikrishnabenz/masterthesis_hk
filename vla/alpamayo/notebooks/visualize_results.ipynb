{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53806b27",
   "metadata": {},
   "source": [
    "# Alpamayo VLA — Comprehensive Visualization Dashboard\n",
    "\n",
    "Visualizes all outputs from Alpamayo-R1-10B inference:\n",
    "1. **BEV trajectory plot** (predicted vs ground truth)\n",
    "2. **Trajectory overlay on camera images**\n",
    "3. **Multi-sample uncertainty fan**\n",
    "4. **Animated trajectory video**\n",
    "5. **Heading arrows on BEV**\n",
    "6. **Reasoning trace display**\n",
    "7. **Multi-camera grid with trajectory**\n",
    "8. **Per-video dashboard**\n",
    "9. **Aggregate metrics charts**\n",
    "\n",
    "**Usage:** Point `RESULTS_DIR` to the inference output directory containing `*_inference.json` and `*_vis_data.npz` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb34caa",
   "metadata": {},
   "source": [
    "## 0 — Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a61390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML, display, Markdown\n",
    "import textwrap\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 120,\n",
    "    \"font.size\": 10,\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 10,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# CONFIGURE THIS: path to the inference output directory\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "RESULTS_DIR = \"/tmp/alpamayo_output\"  # <-- change to your output path\n",
    "\n",
    "# Auto-discover all run directories\n",
    "run_dirs = sorted(glob.glob(os.path.join(RESULTS_DIR, \"*\")))\n",
    "if not run_dirs:\n",
    "    # Maybe RESULTS_DIR itself is the run directory\n",
    "    run_dirs = [RESULTS_DIR]\n",
    "print(f\"Found {len(run_dirs)} run(s): {[os.path.basename(d) for d in run_dirs]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe14a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera name lookup (index -> name)\n",
    "INDEX_TO_CAMERA = {\n",
    "    0: \"cross_left_120fov\",\n",
    "    1: \"front_wide_120fov\",\n",
    "    2: \"cross_right_120fov\",\n",
    "    3: \"rear_left_70fov\",\n",
    "    4: \"rear_tele_30fov\",\n",
    "    5: \"rear_right_70fov\",\n",
    "    6: \"front_tele_30fov\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_video_result(video_dir: str) -> dict:\n",
    "    \"\"\"Load JSON metadata + npz tensor data for one video.\"\"\"\n",
    "    json_files = glob.glob(os.path.join(video_dir, \"*_inference.json\"))\n",
    "    npz_files = glob.glob(os.path.join(video_dir, \"*_vis_data.npz\"))\n",
    "\n",
    "    if not json_files:\n",
    "        # Try one level deeper\n",
    "        json_files = glob.glob(os.path.join(video_dir, \"**\", \"*_inference.json\"), recursive=True)\n",
    "        npz_files = glob.glob(os.path.join(video_dir, \"**\", \"*_vis_data.npz\"), recursive=True)\n",
    "\n",
    "    result = {}\n",
    "    if json_files:\n",
    "        with open(json_files[0]) as f:\n",
    "            result[\"meta\"] = json.load(f)\n",
    "    if npz_files:\n",
    "        result[\"vis\"] = dict(np.load(npz_files[0], allow_pickle=True))\n",
    "    return result\n",
    "\n",
    "\n",
    "def discover_all_videos(results_dir: str) -> list[dict]:\n",
    "    \"\"\"Discover all video results across all runs.\"\"\"\n",
    "    all_videos = []\n",
    "    for run_dir in sorted(glob.glob(os.path.join(results_dir, \"*\"))):\n",
    "        if not os.path.isdir(run_dir):\n",
    "            continue\n",
    "        # Check if run_dir itself has results\n",
    "        result = load_video_result(run_dir)\n",
    "        if result.get(\"meta\"):\n",
    "            all_videos.append(result)\n",
    "            continue\n",
    "        # Otherwise look one level deeper (run_dir/video_id/...)\n",
    "        for video_dir in sorted(glob.glob(os.path.join(run_dir, \"*\"))):\n",
    "            if not os.path.isdir(video_dir):\n",
    "                continue\n",
    "            result = load_video_result(video_dir)\n",
    "            if result.get(\"meta\"):\n",
    "                all_videos.append(result)\n",
    "    return all_videos\n",
    "\n",
    "\n",
    "all_videos = discover_all_videos(RESULTS_DIR)\n",
    "print(f\"Loaded {len(all_videos)} video result(s)\")\n",
    "for v in all_videos:\n",
    "    m = v[\"meta\"]\n",
    "    has_vis = \"vis\" in v\n",
    "    print(f\"  • {m['video_id']}  minADE={m.get('min_ade_meters', 'N/A'):.4f}m  \"\n",
    "          f\"vis_data={'✓' if has_vis else '✗'}  success={m['success']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02af81",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 — BEV Trajectory Plot (Predicted vs Ground Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cf9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bev_trajectory(\n",
    "    pred_xyz: np.ndarray,\n",
    "    gt_xyz: np.ndarray,\n",
    "    history_xyz: Optional[np.ndarray] = None,\n",
    "    title: str = \"BEV Trajectory\",\n",
    "    ax: Optional[plt.Axes] = None,\n",
    "    show_time_coloring: bool = True,\n",
    ") -> plt.Axes:\n",
    "    \"\"\"Bird's-eye-view trajectory plot.\n",
    "\n",
    "    Coordinate convention for display: rotate 90° CCW so forward (x) points up.\n",
    "      display_x = -y_ego,  display_y = x_ego\n",
    "\n",
    "    Args:\n",
    "        pred_xyz: (S, 64, 3) predicted trajectories.\n",
    "        gt_xyz:   (64, 3) ground truth.\n",
    "        history_xyz: (16, 3) optional ego history.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    num_samples = pred_xyz.shape[0]\n",
    "    t_future = np.linspace(0, 6.4, 64)  # seconds\n",
    "    cmap = cm.viridis\n",
    "    norm = Normalize(vmin=0, vmax=6.4)\n",
    "\n",
    "    # History\n",
    "    if history_xyz is not None:\n",
    "        hx, hy = -history_xyz[:, 1], history_xyz[:, 0]\n",
    "        ax.plot(hx, hy, \"s-\", color=\"gray\", markersize=3, linewidth=1.5,\n",
    "                label=\"Ego History (1.6s)\", alpha=0.7, zorder=2)\n",
    "\n",
    "    # Ground truth\n",
    "    gt_dx, gt_dy = -gt_xyz[:, 1], gt_xyz[:, 0]\n",
    "    if show_time_coloring:\n",
    "        points = np.column_stack([gt_dx, gt_dy]).reshape(-1, 1, 2)\n",
    "        segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "        lc = LineCollection(segments, cmap=\"Reds\", norm=norm, linewidth=3, zorder=3)\n",
    "        lc.set_array(t_future[:-1])\n",
    "        ax.add_collection(lc)\n",
    "        ax.plot([], [], \"r-\", linewidth=3, label=\"Ground Truth (6.4s)\")\n",
    "    else:\n",
    "        ax.plot(gt_dx, gt_dy, \"r-\", linewidth=3, label=\"Ground Truth\", zorder=3)\n",
    "\n",
    "    # Predicted trajectories\n",
    "    colors = cm.tab10(np.linspace(0, 1, max(num_samples, 1)))\n",
    "    for s in range(num_samples):\n",
    "        px, py = -pred_xyz[s, :, 1], pred_xyz[s, :, 0]\n",
    "        ax.plot(px, py, \"o-\", color=colors[s % len(colors)], markersize=2,\n",
    "                linewidth=1.5, alpha=0.8, label=f\"Predicted #{s+1}\", zorder=4)\n",
    "\n",
    "    # Origin marker (ego at t0)\n",
    "    ax.plot(0, 0, \"*\", color=\"black\", markersize=14, zorder=5, label=\"Ego at t₀\")\n",
    "\n",
    "    ax.set_xlabel(\"Lateral (m)\")\n",
    "    ax.set_ylabel(\"Forward (m)\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.legend(fontsize=8, loc=\"best\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return ax\n",
    "\n",
    "\n",
    "# Plot for each video\n",
    "for v in all_videos:\n",
    "    if \"vis\" not in v:\n",
    "        continue\n",
    "    vis = v[\"vis\"]\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    plot_bev_trajectory(\n",
    "        pred_xyz=vis[\"pred_xyz\"],\n",
    "        gt_xyz=vis[\"gt_future_xyz\"],\n",
    "        history_xyz=vis[\"ego_history_xyz\"],\n",
    "        title=f\"BEV Trajectory — {v['meta']['video_id']}\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7c182",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 — Trajectory Overlay on Front Camera Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_trajectory_to_image(\n",
    "    traj_xyz: np.ndarray,\n",
    "    img_h: int,\n",
    "    img_w: int,\n",
    "    fov_deg: float = 120.0,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Project 3D ego-frame trajectory onto a front-facing camera image (pinhole approx).\n",
    "\n",
    "    The ego frame has x=forward, y=left, z=up.\n",
    "    The camera frame has z=forward, x=right, y=down.\n",
    "\n",
    "    Returns (u, v, mask) — pixel coordinates and a boolean mask for points\n",
    "    that are in front of the camera and within the image bounds.\n",
    "    \"\"\"\n",
    "    # Approximate intrinsics from horizontal FOV\n",
    "    fov_rad = np.deg2rad(fov_deg)\n",
    "    fx = (img_w / 2.0) / np.tan(fov_rad / 2.0)\n",
    "    fy = fx  # square pixels\n",
    "    cx, cy = img_w / 2.0, img_h / 2.0\n",
    "\n",
    "    # Ego -> camera: x_cam = -y_ego, y_cam = -z_ego, z_cam = x_ego\n",
    "    x_cam = -traj_xyz[:, 1]\n",
    "    y_cam = -traj_xyz[:, 2]\n",
    "    z_cam = traj_xyz[:, 0]   # forward\n",
    "\n",
    "    # Only keep points in front of camera\n",
    "    in_front = z_cam > 0.5\n",
    "\n",
    "    u = np.full_like(z_cam, -1.0)\n",
    "    v = np.full_like(z_cam, -1.0)\n",
    "    u[in_front] = fx * x_cam[in_front] / z_cam[in_front] + cx\n",
    "    v[in_front] = fy * y_cam[in_front] / z_cam[in_front] + cy\n",
    "\n",
    "    in_bounds = in_front & (u >= 0) & (u < img_w) & (v >= 0) & (v < img_h)\n",
    "    return u, v, in_bounds\n",
    "\n",
    "\n",
    "def overlay_trajectory_on_image(\n",
    "    img: np.ndarray,\n",
    "    pred_xyz: np.ndarray,\n",
    "    gt_xyz: np.ndarray,\n",
    "    fov_deg: float = 120.0,\n",
    "    title: str = \"\",\n",
    "    ax: Optional[plt.Axes] = None,\n",
    ") -> plt.Axes:\n",
    "    \"\"\"Overlay predicted + GT trajectories on a camera image.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    h, w = img.shape[:2]\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Ground truth\n",
    "    u_gt, v_gt, mask_gt = project_trajectory_to_image(gt_xyz, h, w, fov_deg)\n",
    "    if mask_gt.any():\n",
    "        ax.plot(u_gt[mask_gt], v_gt[mask_gt], \"o-\", color=\"red\", markersize=4,\n",
    "                linewidth=2, label=\"Ground Truth\", zorder=3)\n",
    "\n",
    "    # Predictions\n",
    "    num_samples = pred_xyz.shape[0]\n",
    "    colors = cm.tab10(np.linspace(0, 1, max(num_samples, 1)))\n",
    "    for s in range(num_samples):\n",
    "        u_p, v_p, mask_p = project_trajectory_to_image(pred_xyz[s], h, w, fov_deg)\n",
    "        if mask_p.any():\n",
    "            ax.plot(u_p[mask_p], v_p[mask_p], \"o-\", color=colors[s % len(colors)],\n",
    "                    markersize=3, linewidth=1.5, alpha=0.9,\n",
    "                    label=f\"Predicted #{s+1}\", zorder=4)\n",
    "\n",
    "    ax.set_title(title or \"Trajectory Overlay\")\n",
    "    ax.legend(fontsize=8, loc=\"lower right\")\n",
    "    ax.axis(\"off\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "# Plot for each video\n",
    "for v in all_videos:\n",
    "    if \"vis\" not in v:\n",
    "        continue\n",
    "    vis = v[\"vis\"]\n",
    "    cam_indices = vis[\"camera_indices\"]  # (N_cam,)\n",
    "    num_cams = len(cam_indices)\n",
    "    num_frames = vis[\"image_frames\"].shape[0] // num_cams\n",
    "\n",
    "    # Find front_wide camera (index 1), use last frame\n",
    "    front_pos = np.where(cam_indices == 1)[0]\n",
    "    if len(front_pos) == 0:\n",
    "        front_pos = [0]  # fallback to first camera\n",
    "    frame_idx = front_pos[0] * num_frames + (num_frames - 1)  # last frame\n",
    "    front_img = vis[\"image_frames\"][frame_idx]\n",
    "\n",
    "    # Determine FOV from camera type\n",
    "    cam_name = v[\"meta\"].get(\"camera_name\", \"camera_front_wide_120fov\")\n",
    "    fov = 120.0 if \"120fov\" in cam_name else 30.0\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    overlay_trajectory_on_image(\n",
    "        img=front_img,\n",
    "        pred_xyz=vis[\"pred_xyz\"],\n",
    "        gt_xyz=vis[\"gt_future_xyz\"],\n",
    "        fov_deg=120.0,  # front_wide is 120°\n",
    "        title=f\"Trajectory Overlay — {v['meta']['video_id']}\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6016039b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 — Multi-Sample Uncertainty Fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uncertainty_fan(\n",
    "    pred_xyz: np.ndarray,\n",
    "    gt_xyz: np.ndarray,\n",
    "    history_xyz: Optional[np.ndarray] = None,\n",
    "    title: str = \"Trajectory Uncertainty Fan\",\n",
    "    ax: Optional[plt.Axes] = None,\n",
    ") -> plt.Axes:\n",
    "    \"\"\"Plot all trajectory samples with a filled uncertainty region.\n",
    "\n",
    "    Args:\n",
    "        pred_xyz: (S, 64, 3) — multiple trajectory samples.\n",
    "        gt_xyz:   (64, 3) ground truth.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    S = pred_xyz.shape[0]\n",
    "    # Rotate to display frame: dx = -y, dy = x\n",
    "    pred_dx = -pred_xyz[:, :, 1]  # (S, 64)\n",
    "    pred_dy = pred_xyz[:, :, 0]   # (S, 64)\n",
    "\n",
    "    gt_dx = -gt_xyz[:, 1]\n",
    "    gt_dy = gt_xyz[:, 0]\n",
    "\n",
    "    if S > 1:\n",
    "        # Compute per-timestep mean and spread\n",
    "        mean_dx = pred_dx.mean(axis=0)\n",
    "        mean_dy = pred_dy.mean(axis=0)\n",
    "        std_dx = pred_dx.std(axis=0)\n",
    "        std_dy = pred_dy.std(axis=0)\n",
    "\n",
    "        # Uncertainty ellipse at each timestep (approx as ±2σ band)\n",
    "        ax.fill_between(\n",
    "            mean_dx,\n",
    "            mean_dy - 2 * std_dy,\n",
    "            mean_dy + 2 * std_dy,\n",
    "            alpha=0.15, color=\"blue\", label=\"±2σ spread\", zorder=1,\n",
    "        )\n",
    "        ax.fill_between(\n",
    "            mean_dx,\n",
    "            mean_dy - std_dy,\n",
    "            mean_dy + std_dy,\n",
    "            alpha=0.25, color=\"blue\", label=\"±1σ spread\", zorder=1,\n",
    "        )\n",
    "        # Mean trajectory\n",
    "        ax.plot(mean_dx, mean_dy, \"-\", color=\"blue\", linewidth=2,\n",
    "                label=\"Mean Prediction\", zorder=4)\n",
    "\n",
    "    # Individual samples\n",
    "    colors = cm.cool(np.linspace(0.2, 0.8, S))\n",
    "    for s in range(S):\n",
    "        ax.plot(pred_dx[s], pred_dy[s], \"-\", color=colors[s], alpha=0.5,\n",
    "                linewidth=0.8, zorder=3)\n",
    "\n",
    "    # Ground truth\n",
    "    ax.plot(gt_dx, gt_dy, \"r-\", linewidth=3, label=\"Ground Truth\", zorder=5)\n",
    "\n",
    "    # History\n",
    "    if history_xyz is not None:\n",
    "        hx, hy = -history_xyz[:, 1], history_xyz[:, 0]\n",
    "        ax.plot(hx, hy, \"s-\", color=\"gray\", markersize=3, linewidth=1.5,\n",
    "                label=\"History\", alpha=0.7, zorder=2)\n",
    "\n",
    "    ax.plot(0, 0, \"*\", color=\"black\", markersize=14, zorder=6)\n",
    "    ax.set_xlabel(\"Lateral (m)\")\n",
    "    ax.set_ylabel(\"Forward (m)\")\n",
    "    ax.set_title(f\"{title}  (S={S} samples)\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.legend(fontsize=8, loc=\"best\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return ax\n",
    "\n",
    "\n",
    "for v in all_videos:\n",
    "    if \"vis\" not in v:\n",
    "        continue\n",
    "    vis = v[\"vis\"]\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    plot_uncertainty_fan(\n",
    "        pred_xyz=vis[\"pred_xyz\"],\n",
    "        gt_xyz=vis[\"gt_future_xyz\"],\n",
    "        history_xyz=vis[\"ego_history_xyz\"],\n",
    "        title=f\"Uncertainty — {v['meta']['video_id']}\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393fa76",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 — Animated Trajectory Video (6.4s rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803da41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trajectory_animation(\n",
    "    pred_xyz: np.ndarray,\n",
    "    gt_xyz: np.ndarray,\n",
    "    history_xyz: Optional[np.ndarray] = None,\n",
    "    title: str = \"Trajectory Rollout\",\n",
    "    interval_ms: int = 100,\n",
    ") -> animation.FuncAnimation:\n",
    "    \"\"\"Create frame-by-frame animation of the trajectory unfolding.\n",
    "\n",
    "    Each animation frame reveals one more waypoint (at 10 Hz → 64 frames).\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    num_steps = pred_xyz.shape[1]  # 64\n",
    "    S = pred_xyz.shape[0]\n",
    "\n",
    "    # Compute axis limits from all data\n",
    "    all_x = np.concatenate([-pred_xyz[:, :, 1].flatten(), -gt_xyz[:, 1]])\n",
    "    all_y = np.concatenate([pred_xyz[:, :, 0].flatten(), gt_xyz[:, 0]])\n",
    "    if history_xyz is not None:\n",
    "        all_x = np.concatenate([all_x, -history_xyz[:, 1]])\n",
    "        all_y = np.concatenate([all_y, history_xyz[:, 0]])\n",
    "    margin = 5\n",
    "    xlim = (all_x.min() - margin, all_x.max() + margin)\n",
    "    ylim = (all_y.min() - margin, all_y.max() + margin)\n",
    "\n",
    "    colors = cm.tab10(np.linspace(0, 1, max(S, 1)))\n",
    "\n",
    "    def init():\n",
    "        ax.clear()\n",
    "        return []\n",
    "\n",
    "    def update(frame_idx):\n",
    "        ax.clear()\n",
    "        t = frame_idx + 1  # number of waypoints to show\n",
    "\n",
    "        # History (always full)\n",
    "        if history_xyz is not None:\n",
    "            hx, hy = -history_xyz[:, 1], history_xyz[:, 0]\n",
    "            ax.plot(hx, hy, \"s-\", color=\"gray\", markersize=3,\n",
    "                    linewidth=1.5, alpha=0.7, label=\"History\")\n",
    "\n",
    "        # Ground truth up to t\n",
    "        gt_dx, gt_dy = -gt_xyz[:t, 1], gt_xyz[:t, 0]\n",
    "        ax.plot(gt_dx, gt_dy, \"r-\", linewidth=3, label=\"Ground Truth\")\n",
    "        if t > 0:\n",
    "            ax.plot(gt_dx[-1], gt_dy[-1], \"ro\", markersize=8)\n",
    "\n",
    "        # Predicted up to t\n",
    "        for s in range(S):\n",
    "            px, py = -pred_xyz[s, :t, 1], pred_xyz[s, :t, 0]\n",
    "            ax.plot(px, py, \"o-\", color=colors[s % len(colors)], markersize=2,\n",
    "                    linewidth=1.5, alpha=0.8, label=f\"Pred #{s+1}\")\n",
    "            if t > 0:\n",
    "                ax.plot(px[-1], py[-1], \"o\", color=colors[s % len(colors)], markersize=6)\n",
    "\n",
    "        ax.plot(0, 0, \"*\", color=\"black\", markersize=14)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_xlabel(\"Lateral (m)\")\n",
    "        ax.set_ylabel(\"Forward (m)\")\n",
    "        ax.set_title(f\"{title}  t={t*0.1:.1f}s / 6.4s\")\n",
    "        ax.legend(fontsize=7, loc=\"upper left\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        return []\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update, init_func=init,\n",
    "        frames=num_steps, interval=interval_ms, blit=False,\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    return anim\n",
    "\n",
    "\n",
    "# Show animation for the first video\n",
    "for v in all_videos[:1]:\n",
    "    if \"vis\" not in v:\n",
    "        continue\n",
    "    vis = v[\"vis\"]\n",
    "    anim = create_trajectory_animation(\n",
    "        pred_xyz=vis[\"pred_xyz\"],\n",
    "        gt_xyz=vis[\"gt_future_xyz\"],\n",
    "        history_xyz=vis[\"ego_history_xyz\"],\n",
    "        title=v[\"meta\"][\"video_id\"],\n",
    "    )\n",
    "    display(HTML(anim.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593bd77",
   "metadata": {},
   "source": [
    "---\n",
    "## 5 — Heading Arrows on BEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4598259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_yaw_from_rotation_matrix(rot: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Extract yaw angle from SO(3) rotation matrices.\n",
    "\n",
    "    rot: (..., 3, 3) -> yaw in radians (...,)\n",
    "    The yaw is atan2(R[1,0], R[0,0]) — rotation about the z-axis.\n",
    "    \"\"\"\n",
    "    return np.arctan2(rot[..., 1, 0], rot[..., 0, 0])\n",
    "\n",
    "\n",
    "def plot_bev_with_heading(\n",
    "    pred_xyz: np.ndarray,\n",
    "    pred_rot: np.ndarray,\n",
    "    gt_xyz: np.ndarray,\n",
    "    gt_rot: np.ndarray,\n",
    "    history_xyz: Optional[np.ndarray] = None,\n",
    "    history_rot: Optional[np.ndarray] = None,\n",
    "    title: str = \"BEV + Heading Arrows\",\n",
    "    arrow_every: int = 8,\n",
    "    arrow_length: float = 1.5,\n",
    "    ax: Optional[plt.Axes] = None,\n",
    ") -> plt.Axes:\n",
    "    \"\"\"BEV plot with yaw heading arrows at regular intervals.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    S = pred_xyz.shape[0]\n",
    "\n",
    "    # History\n",
    "    if history_xyz is not None:\n",
    "        hx, hy = -history_xyz[:, 1], history_xyz[:, 0]\n",
    "        ax.plot(hx, hy, \"s-\", color=\"gray\", markersize=3, linewidth=1.5,\n",
    "                label=\"History\", alpha=0.7)\n",
    "        if history_rot is not None:\n",
    "            yaw_h = extract_yaw_from_rotation_matrix(history_rot)\n",
    "            for i in range(0, len(hx), arrow_every):\n",
    "                # Arrow direction in display frame: rotate yaw by 90° CCW\n",
    "                dx = -np.sin(yaw_h[i]) * arrow_length\n",
    "                dy = np.cos(yaw_h[i]) * arrow_length\n",
    "                ax.annotate(\"\", xy=(hx[i]+dx, hy[i]+dy), xytext=(hx[i], hy[i]),\n",
    "                            arrowprops=dict(arrowstyle=\"->\", color=\"gray\", lw=1.5))\n",
    "\n",
    "    # Ground truth with arrows\n",
    "    gt_dx, gt_dy = -gt_xyz[:, 1], gt_xyz[:, 0]\n",
    "    ax.plot(gt_dx, gt_dy, \"r-\", linewidth=3, label=\"Ground Truth\", zorder=3)\n",
    "    yaw_gt = extract_yaw_from_rotation_matrix(gt_rot)\n",
    "    for i in range(0, len(gt_dx), arrow_every):\n",
    "        dx = -np.sin(yaw_gt[i]) * arrow_length\n",
    "        dy = np.cos(yaw_gt[i]) * arrow_length\n",
    "        ax.annotate(\"\", xy=(gt_dx[i]+dx, gt_dy[i]+dy), xytext=(gt_dx[i], gt_dy[i]),\n",
    "                    arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2), zorder=5)\n",
    "\n",
    "    # Predicted with arrows\n",
    "    colors = cm.tab10(np.linspace(0, 1, max(S, 1)))\n",
    "    for s in range(S):\n",
    "        px, py = -pred_xyz[s, :, 1], pred_xyz[s, :, 0]\n",
    "        ax.plot(px, py, \"o-\", color=colors[s % len(colors)], markersize=2,\n",
    "                linewidth=1.5, alpha=0.8, label=f\"Pred #{s+1}\", zorder=4)\n",
    "        yaw_p = extract_yaw_from_rotation_matrix(pred_rot[s])\n",
    "        for i in range(0, len(px), arrow_every):\n",
    "            dx = -np.sin(yaw_p[i]) * arrow_length\n",
    "            dy = np.cos(yaw_p[i]) * arrow_length\n",
    "            ax.annotate(\"\", xy=(px[i]+dx, py[i]+dy), xytext=(px[i], py[i]),\n",
    "                        arrowprops=dict(arrowstyle=\"->\", color=colors[s % len(colors)],\n",
    "                                        lw=1.5, alpha=0.8), zorder=5)\n",
    "\n",
    "    ax.plot(0, 0, \"*\", color=\"black\", markersize=14, zorder=6)\n",
    "    ax.set_xlabel(\"Lateral (m)\")\n",
    "    ax.set_ylabel(\"Forward (m)\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.legend(fontsize=8, loc=\"best\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return ax\n",
    "\n",
    "\n",
    "for v in all_videos:\n",
    "    if \"vis\" not in v:\n",
    "        continue\n",
    "    vis = v[\"vis\"]\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plot_bev_with_heading(\n",
    "        pred_xyz=vis[\"pred_xyz\"],\n",
    "        pred_rot=vis[\"pred_rot\"],\n",
    "        gt_xyz=vis[\"gt_future_xyz\"],\n",
    "        gt_rot=vis[\"gt_future_rot\"],\n",
    "        history_xyz=vis[\"ego_history_xyz\"],\n",
    "        history_rot=vis[\"ego_history_rot\"],\n",
    "        title=f\"Heading Arrows — {v['meta']['video_id']}\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e769f5",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 — Reasoning Trace (Chain-of-Causation) Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c880904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_reasoning_traces(video_result: dict):\n",
    "    \"\"\"Display CoC reasoning traces alongside the front camera image.\"\"\"\n",
    "    meta = video_result[\"meta\"]\n",
    "    traces = meta.get(\"reasoning_traces\", [])\n",
    "    has_vis = \"vis\" in video_result\n",
    "\n",
    "    if has_vis:\n",
    "        vis = video_result[\"vis\"]\n",
    "        cam_indices = vis[\"camera_indices\"]\n",
    "        num_cams = len(cam_indices)\n",
    "        num_frames = vis[\"image_frames\"].shape[0] // num_cams\n",
    "\n",
    "        # Find front_wide camera\n",
    "        front_pos = np.where(cam_indices == 1)[0]\n",
    "        if len(front_pos) == 0:\n",
    "            front_pos = [0]\n",
    "        frame_idx = front_pos[0] * num_frames + (num_frames - 1)\n",
    "        front_img = vis[\"image_frames\"][frame_idx]\n",
    "\n",
    "        fig, (ax_img, ax_txt) = plt.subplots(1, 2, figsize=(16, 5),\n",
    "                                              gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "        ax_img.imshow(front_img)\n",
    "        ax_img.set_title(f\"Front Camera — {meta['video_id']}\")\n",
    "        ax_img.axis(\"off\")\n",
    "    else:\n",
    "        fig, ax_txt = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Reasoning text\n",
    "    ax_txt.axis(\"off\")\n",
    "    ax_txt.set_title(\"Chain-of-Causation Reasoning\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    if not traces:\n",
    "        ax_txt.text(0.05, 0.5, \"No reasoning traces available.\",\n",
    "                    transform=ax_txt.transAxes, fontsize=10, va=\"center\")\n",
    "    else:\n",
    "        y_pos = 0.95\n",
    "        for i, trace in enumerate(traces):\n",
    "            wrapped = textwrap.fill(trace.strip(), width=60)\n",
    "            header = f\"Trajectory #{i+1}:\"\n",
    "            ax_txt.text(0.02, y_pos, header, transform=ax_txt.transAxes,\n",
    "                        fontsize=9, fontweight=\"bold\", va=\"top\",\n",
    "                        fontfamily=\"monospace\")\n",
    "            y_pos -= 0.06\n",
    "            ax_txt.text(0.02, y_pos, wrapped, transform=ax_txt.transAxes,\n",
    "                        fontsize=8, va=\"top\", fontfamily=\"serif\",\n",
    "                        linespacing=1.4)\n",
    "            # Estimate vertical space used\n",
    "            num_lines = wrapped.count(\"\\n\") + 1\n",
    "            y_pos -= 0.05 * num_lines + 0.04\n",
    "            if y_pos < 0.05:\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Also print full text for copy-paste\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Reasoning Traces for: {meta['video_id']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for i, trace in enumerate(traces):\n",
    "        print(f\"\\n--- Trajectory #{i+1} ---\")\n",
    "        print(trace.strip())\n",
    "\n",
    "\n",
    "for v in all_videos:\n",
    "    display_reasoning_traces(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e80c72",
   "metadata": {},
   "source": [
    "---\n",
    "## 7 — Multi-Camera Grid with BEV Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multicam_grid_with_bev(video_result: dict):\n",
    "    \"\"\"Show all camera views (last frame each) tiled alongside BEV trajectory.\"\"\"\n",
    "    if \"vis\" not in video_result:\n",
    "        print(f\"No visualization data for {video_result['meta']['video_id']}\")\n",
    "        return\n",
    "\n",
    "    meta = video_result[\"meta\"]\n",
    "    vis = video_result[\"vis\"]\n",
    "    cam_indices = vis[\"camera_indices\"]\n",
    "    num_cams = len(cam_indices)\n",
    "    num_frames_per_cam = vis[\"image_frames\"].shape[0] // num_cams\n",
    "\n",
    "    # Layout: top row = cameras, bottom = BEV plot\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = GridSpec(2, num_cams, figure=fig, height_ratios=[1, 1.2], hspace=0.25, wspace=0.05)\n",
    "\n",
    "    # Top row: camera views (last frame of each camera)\n",
    "    for c in range(num_cams):\n",
    "        ax_cam = fig.add_subplot(gs[0, c])\n",
    "        frame_idx = c * num_frames_per_cam + (num_frames_per_cam - 1)  # last frame\n",
    "        img = vis[\"image_frames\"][frame_idx]\n",
    "        ax_cam.imshow(img)\n",
    "        cam_name = INDEX_TO_CAMERA.get(int(cam_indices[c]), f\"cam_{cam_indices[c]}\")\n",
    "        ax_cam.set_title(cam_name, fontsize=9)\n",
    "        ax_cam.axis(\"off\")\n",
    "\n",
    "    # Bottom row: BEV trajectory spanning all columns\n",
    "    ax_bev = fig.add_subplot(gs[1, :])\n",
    "    plot_bev_trajectory(\n",
    "        pred_xyz=vis[\"pred_xyz\"],\n",
    "        gt_xyz=vis[\"gt_future_xyz\"],\n",
    "        history_xyz=vis[\"ego_history_xyz\"],\n",
    "        title=f\"BEV Trajectory — {meta['video_id']}\",\n",
    "        ax=ax_bev,\n",
    "    )\n",
    "\n",
    "    fig.suptitle(f\"Multi-Camera View + BEV — {meta['video_id']}\", fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for v in all_videos:\n",
    "    plot_multicam_grid_with_bev(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec75cc1",
   "metadata": {},
   "source": [
    "---\n",
    "## 8 — Per-Video Dashboard (cameras + BEV + reasoning + metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_dashboard(video_result: dict):\n",
    "    \"\"\"Complete per-video dashboard combining all visual outputs.\"\"\"\n",
    "    meta = video_result[\"meta\"]\n",
    "    has_vis = \"vis\" in video_result\n",
    "\n",
    "    if not has_vis:\n",
    "        print(f\"No visualization data for {meta['video_id']}\")\n",
    "        return\n",
    "\n",
    "    vis = video_result[\"vis\"]\n",
    "    cam_indices = vis[\"camera_indices\"]\n",
    "    num_cams = len(cam_indices)\n",
    "    num_frames_per_cam = vis[\"image_frames\"].shape[0] // num_cams\n",
    "\n",
    "    # Layout:\n",
    "    # Row 0: 4 camera views\n",
    "    # Row 1: [BEV trajectory] [BEV with heading]\n",
    "    # Row 2: [Reasoning text] [Metrics table]\n",
    "    fig = plt.figure(figsize=(20, 18))\n",
    "    gs = GridSpec(3, 4, figure=fig, height_ratios=[0.8, 1.2, 0.8],\n",
    "                  hspace=0.3, wspace=0.3)\n",
    "\n",
    "    # ── Row 0: Camera views ──\n",
    "    for c in range(min(num_cams, 4)):\n",
    "        ax = fig.add_subplot(gs[0, c])\n",
    "        frame_idx = c * num_frames_per_cam + (num_frames_per_cam - 1)\n",
    "        ax.imshow(vis[\"image_frames\"][frame_idx])\n",
    "        cam_name = INDEX_TO_CAMERA.get(int(cam_indices[c]), f\"cam_{cam_indices[c]}\")\n",
    "        ax.set_title(cam_name, fontsize=9)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # ── Row 1 left: BEV trajectory ──\n",
    "    ax_bev = fig.add_subplot(gs[1, :2])\n",
    "    plot_bev_trajectory(\n",
    "        pred_xyz=vis[\"pred_xyz\"],\n",
    "        gt_xyz=vis[\"gt_future_xyz\"],\n",
    "        history_xyz=vis[\"ego_history_xyz\"],\n",
    "        title=\"BEV Trajectory\",\n",
    "        ax=ax_bev,\n",
    "    )\n",
    "\n",
    "    # ── Row 1 right: BEV with heading arrows ──\n",
    "    ax_heading = fig.add_subplot(gs[1, 2:])\n",
    "    plot_bev_with_heading(\n",
    "        pred_xyz=vis[\"pred_xyz\"],\n",
    "        pred_rot=vis[\"pred_rot\"],\n",
    "        gt_xyz=vis[\"gt_future_xyz\"],\n",
    "        gt_rot=vis[\"gt_future_rot\"],\n",
    "        history_xyz=vis[\"ego_history_xyz\"],\n",
    "        history_rot=vis[\"ego_history_rot\"],\n",
    "        title=\"BEV + Heading\",\n",
    "        ax=ax_heading,\n",
    "    )\n",
    "\n",
    "    # ── Row 2 left: Reasoning trace ──\n",
    "    ax_cot = fig.add_subplot(gs[2, :2])\n",
    "    ax_cot.axis(\"off\")\n",
    "    ax_cot.set_title(\"Chain-of-Causation Reasoning\", fontsize=11, fontweight=\"bold\",\n",
    "                     loc=\"left\")\n",
    "    traces = meta.get(\"reasoning_traces\", [])\n",
    "    if traces:\n",
    "        y_pos = 0.95\n",
    "        for i, trace in enumerate(traces[:3]):  # max 3 traces\n",
    "            wrapped = textwrap.fill(trace.strip(), width=80)\n",
    "            ax_cot.text(0.02, y_pos, f\"Traj #{i+1}: {wrapped}\",\n",
    "                        transform=ax_cot.transAxes, fontsize=7.5, va=\"top\",\n",
    "                        fontfamily=\"serif\", linespacing=1.3)\n",
    "            num_lines = wrapped.count(\"\\n\") + 1\n",
    "            y_pos -= 0.04 * num_lines + 0.06\n",
    "    else:\n",
    "        ax_cot.text(0.02, 0.5, \"No reasoning traces.\",\n",
    "                    transform=ax_cot.transAxes, fontsize=10, va=\"center\")\n",
    "\n",
    "    # ── Row 2 right: Metrics table ──\n",
    "    ax_metrics = fig.add_subplot(gs[2, 2:])\n",
    "    ax_metrics.axis(\"off\")\n",
    "    ax_metrics.set_title(\"Inference Metrics\", fontsize=11, fontweight=\"bold\", loc=\"left\")\n",
    "\n",
    "    metrics = meta.get(\"metrics\", {})\n",
    "    table_data = [\n",
    "        [\"Video ID\", meta.get(\"video_id\", \"N/A\")],\n",
    "        [\"Clip ID\", meta.get(\"clip_id\", \"N/A\")],\n",
    "        [\"Camera\", meta.get(\"camera_name\", \"N/A\")],\n",
    "        [\"minADE\", f\"{meta.get('min_ade_meters', 0):.4f} m\"],\n",
    "        [\"# Trajectories\", str(meta.get(\"num_trajectories\", 0))],\n",
    "        [\"Inference Time\", f\"{metrics.get('inference_time_seconds', 0):.1f} s\"],\n",
    "        [\"GPU Peak\", f\"{metrics.get('gpu_memory_peak_gb', 0):.2f} GB\"],\n",
    "        [\"RAM Peak\", f\"{metrics.get('ram_peak_mb', 0):.0f} MB\"],\n",
    "        [\"FPS (video)\", f\"{meta.get('temporal_config', {}).get('vp_video_fps', 'N/A')}\"],\n",
    "        [\"Status\", \"SUCCESS\" if meta.get(\"success\") else \"FAILED\"],\n",
    "    ]\n",
    "    table = ax_metrics.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=[\"Metric\", \"Value\"],\n",
    "        loc=\"center\",\n",
    "        cellLoc=\"left\",\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 1.4)\n",
    "    # Style header\n",
    "    for j in range(2):\n",
    "        table[0, j].set_facecolor(\"#4472C4\")\n",
    "        table[0, j].set_text_props(color=\"white\", fontweight=\"bold\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Alpamayo VLA Dashboard — {meta['video_id']}\",\n",
    "        fontsize=16, fontweight=\"bold\", y=1.01,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for v in all_videos:\n",
    "    plot_full_dashboard(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26578381",
   "metadata": {},
   "source": [
    "---\n",
    "## 9 — Aggregate Metrics Charts (across all videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aggregate_metrics(all_videos: list[dict]):\n",
    "    \"\"\"Bar/box plots of minADE, inference time, GPU memory across all videos.\"\"\"\n",
    "    # Gather metrics\n",
    "    video_ids = []\n",
    "    min_ades = []\n",
    "    inf_times = []\n",
    "    gpu_peaks = []\n",
    "    ram_peaks = []\n",
    "    statuses = []\n",
    "\n",
    "    for v in all_videos:\n",
    "        m = v[\"meta\"]\n",
    "        metrics = m.get(\"metrics\", {})\n",
    "        vid = m.get(\"video_id\", \"unknown\")\n",
    "        # Truncate long names for display\n",
    "        short_id = vid[:25] + \"…\" if len(vid) > 25 else vid\n",
    "\n",
    "        video_ids.append(short_id)\n",
    "        min_ades.append(m.get(\"min_ade_meters\", float(\"nan\")))\n",
    "        inf_times.append(metrics.get(\"inference_time_seconds\", 0))\n",
    "        gpu_peaks.append(metrics.get(\"gpu_memory_peak_gb\", 0))\n",
    "        ram_peaks.append(metrics.get(\"ram_peak_mb\", 0))\n",
    "        statuses.append(\"green\" if m.get(\"success\") else \"red\")\n",
    "\n",
    "    n = len(video_ids)\n",
    "    x = np.arange(n)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "    # 1. minADE bar chart\n",
    "    ax = axes[0, 0]\n",
    "    bars = ax.bar(x, min_ades, color=statuses, alpha=0.8, edgecolor=\"black\", linewidth=0.5)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(video_ids, rotation=45, ha=\"right\", fontsize=7)\n",
    "    ax.set_ylabel(\"minADE (meters)\")\n",
    "    ax.set_title(\"minADE per Video\")\n",
    "    ax.axhline(np.nanmean(min_ades), color=\"blue\", linestyle=\"--\", linewidth=1,\n",
    "               label=f\"Mean: {np.nanmean(min_ades):.4f}m\")\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # 2. Inference time bar chart\n",
    "    ax = axes[0, 1]\n",
    "    ax.bar(x, inf_times, color=\"#4472C4\", alpha=0.8, edgecolor=\"black\", linewidth=0.5)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(video_ids, rotation=45, ha=\"right\", fontsize=7)\n",
    "    ax.set_ylabel(\"Time (seconds)\")\n",
    "    ax.set_title(\"Inference Time per Video\")\n",
    "    ax.axhline(np.mean(inf_times), color=\"red\", linestyle=\"--\", linewidth=1,\n",
    "               label=f\"Mean: {np.mean(inf_times):.1f}s\")\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # 3. GPU memory peak bar chart\n",
    "    ax = axes[1, 0]\n",
    "    ax.bar(x, gpu_peaks, color=\"#ED7D31\", alpha=0.8, edgecolor=\"black\", linewidth=0.5)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(video_ids, rotation=45, ha=\"right\", fontsize=7)\n",
    "    ax.set_ylabel(\"GPU Memory Peak (GB)\")\n",
    "    ax.set_title(\"GPU Memory Peak per Video\")\n",
    "    ax.axhline(np.mean(gpu_peaks), color=\"red\", linestyle=\"--\", linewidth=1,\n",
    "               label=f\"Mean: {np.mean(gpu_peaks):.2f} GB\")\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # 4. Box plot summary (minADE + inference time + GPU)\n",
    "    ax = axes[1, 1]\n",
    "    valid_ades = [a for a in min_ades if not np.isnan(a)]\n",
    "    box_data = []\n",
    "    box_labels = []\n",
    "    if valid_ades:\n",
    "        box_data.append(valid_ades)\n",
    "        box_labels.append(f\"minADE\\n(m)\")\n",
    "    if inf_times:\n",
    "        box_data.append(inf_times)\n",
    "        box_labels.append(f\"Inf Time\\n(s)\")\n",
    "    if gpu_peaks:\n",
    "        box_data.append(gpu_peaks)\n",
    "        box_labels.append(f\"GPU Peak\\n(GB)\")\n",
    "    if ram_peaks:\n",
    "        # Convert to GB for better display range\n",
    "        box_data.append([r / 1024 for r in ram_peaks])\n",
    "        box_labels.append(f\"RAM Peak\\n(GB)\")\n",
    "\n",
    "    if box_data:\n",
    "        bp = ax.boxplot(box_data, labels=box_labels, patch_artist=True,\n",
    "                        medianprops={\"color\": \"red\", \"linewidth\": 2})\n",
    "        box_colors = [\"#4472C4\", \"#ED7D31\", \"#A5A5A5\", \"#70AD47\"]\n",
    "        for patch, color in zip(bp[\"boxes\"], box_colors[:len(bp[\"boxes\"])]):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.6)\n",
    "    ax.set_title(\"Metric Distributions\")\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Aggregate Metrics — {n} video(s)\",\n",
    "        fontsize=14, fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary table\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"AGGREGATE SUMMARY ({n} videos)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  minADE — mean: {np.nanmean(min_ades):.4f}m, \"\n",
    "          f\"median: {np.nanmedian(min_ades):.4f}m, \"\n",
    "          f\"best: {np.nanmin(min_ades):.4f}m, \"\n",
    "          f\"worst: {np.nanmax(min_ades):.4f}m\")\n",
    "    print(f\"  Time  — mean: {np.mean(inf_times):.1f}s, \"\n",
    "          f\"total: {sum(inf_times):.1f}s ({sum(inf_times)/60:.1f}min)\")\n",
    "    print(f\"  GPU   — mean peak: {np.mean(gpu_peaks):.2f} GB, \"\n",
    "          f\"max peak: {max(gpu_peaks):.2f} GB\")\n",
    "    print(f\"  RAM   — mean peak: {np.mean(ram_peaks):.0f} MB, \"\n",
    "          f\"max peak: {max(ram_peaks):.0f} MB\")\n",
    "    success_count = sum(1 for s in statuses if s == \"green\")\n",
    "    print(f\"  Status: {success_count}/{n} successful\")\n",
    "\n",
    "\n",
    "plot_aggregate_metrics(all_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2d839",
   "metadata": {},
   "source": [
    "---\n",
    "## Save All Figures to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save all dashboards as PNG for reports\n",
    "SAVE_DIR = os.path.join(RESULTS_DIR, \"visualizations\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "for v in all_videos:\n",
    "    if \"vis\" not in v:\n",
    "        continue\n",
    "    meta = v[\"meta\"]\n",
    "    vis = v[\"vis\"]\n",
    "    vid = meta[\"video_id\"]\n",
    "\n",
    "    # BEV\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    plot_bev_trajectory(vis[\"pred_xyz\"], vis[\"gt_future_xyz\"],\n",
    "                        vis[\"ego_history_xyz\"], title=f\"BEV — {vid}\", ax=ax)\n",
    "    fig.savefig(os.path.join(SAVE_DIR, f\"{vid}_bev.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # BEV + heading\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plot_bev_with_heading(\n",
    "        vis[\"pred_xyz\"], vis[\"pred_rot\"],\n",
    "        vis[\"gt_future_xyz\"], vis[\"gt_future_rot\"],\n",
    "        vis[\"ego_history_xyz\"], vis[\"ego_history_rot\"],\n",
    "        title=f\"Heading — {vid}\", ax=ax,\n",
    "    )\n",
    "    fig.savefig(os.path.join(SAVE_DIR, f\"{vid}_heading.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Uncertainty fan\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    plot_uncertainty_fan(vis[\"pred_xyz\"], vis[\"gt_future_xyz\"],\n",
    "                         vis[\"ego_history_xyz\"], title=f\"Uncertainty — {vid}\", ax=ax)\n",
    "    fig.savefig(os.path.join(SAVE_DIR, f\"{vid}_uncertainty.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Saved visualizations to: {SAVE_DIR}\")\n",
    "print(f\"Files: {sorted(os.listdir(SAVE_DIR))}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
